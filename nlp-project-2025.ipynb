{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11616505,"sourceType":"datasetVersion","datasetId":7287106}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport re\nimport string\nimport time\nimport yaml # For config simulation\nimport shutil # For cleaning up directories\nimport joblib # For saving sklearn models\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:10:12.524030Z","iopub.execute_input":"2025-04-28T15:10:12.524738Z","iopub.status.idle":"2025-04-28T15:10:12.529680Z","shell.execute_reply.started":"2025-04-28T15:10:12.524710Z","shell.execute_reply":"2025-04-28T15:10:12.528758Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# Force reinstall transformers to try and fix environment issues\nprint(\"Force reinstalling transformers==4.39.3...\")\n!pip uninstall transformers -y --quiet\n!pip install transformers==4.39.3 --upgrade --no-deps --quiet\nprint(\"Reinstall complete.\")\n\n# Verify version immediately after reinstall\nimport transformers\nprint(f\"Version after reinstall: {transformers.__version__}\")\n\n# Explicitly import and inspect TrainingArguments\nfrom transformers import TrainingArguments\nimport inspect\nprint(\"\\nInspecting imported TrainingArguments signature:\")\ntry:\n    sig = inspect.signature(TrainingArguments.__init__)\n    print(sig)\nexcept Exception as e:\n    print(f\"Could not inspect signature: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:10:12.531124Z","iopub.execute_input":"2025-04-28T15:10:12.531364Z","iopub.status.idle":"2025-04-28T15:10:21.734308Z","shell.execute_reply.started":"2025-04-28T15:10:12.531340Z","shell.execute_reply":"2025-04-28T15:10:21.733288Z"}},"outputs":[{"name":"stdout","text":"Force reinstalling transformers==4.39.3...\nReinstall complete.\nVersion after reinstall: 4.51.1\n\nInspecting imported TrainingArguments signature:\n(self, output_dir: Optional[str] = None, overwrite_output_dir: bool = False, do_train: bool = False, do_eval: bool = False, do_predict: bool = False, eval_strategy: Union[transformers.trainer_utils.IntervalStrategy, str] = 'no', prediction_loss_only: bool = False, per_device_train_batch_size: int = 8, per_device_eval_batch_size: int = 8, per_gpu_train_batch_size: Optional[int] = None, per_gpu_eval_batch_size: Optional[int] = None, gradient_accumulation_steps: int = 1, eval_accumulation_steps: Optional[int] = None, eval_delay: Optional[float] = 0, torch_empty_cache_steps: Optional[int] = None, learning_rate: float = 5e-05, weight_decay: float = 0.0, adam_beta1: float = 0.9, adam_beta2: float = 0.999, adam_epsilon: float = 1e-08, max_grad_norm: float = 1.0, num_train_epochs: float = 3.0, max_steps: int = -1, lr_scheduler_type: Union[transformers.trainer_utils.SchedulerType, str] = 'linear', lr_scheduler_kwargs: Union[dict, str, NoneType] = <factory>, warmup_ratio: float = 0.0, warmup_steps: int = 0, log_level: Optional[str] = 'passive', log_level_replica: Optional[str] = 'warning', log_on_each_node: bool = True, logging_dir: Optional[str] = None, logging_strategy: Union[transformers.trainer_utils.IntervalStrategy, str] = 'steps', logging_first_step: bool = False, logging_steps: float = 500, logging_nan_inf_filter: bool = True, save_strategy: Union[transformers.trainer_utils.SaveStrategy, str] = 'steps', save_steps: float = 500, save_total_limit: Optional[int] = None, save_safetensors: Optional[bool] = True, save_on_each_node: bool = False, save_only_model: bool = False, restore_callback_states_from_checkpoint: bool = False, no_cuda: bool = False, use_cpu: bool = False, use_mps_device: bool = False, seed: int = 42, data_seed: Optional[int] = None, jit_mode_eval: bool = False, use_ipex: bool = False, bf16: bool = False, fp16: bool = False, fp16_opt_level: str = 'O1', half_precision_backend: str = 'auto', bf16_full_eval: bool = False, fp16_full_eval: bool = False, tf32: Optional[bool] = None, local_rank: int = -1, ddp_backend: Optional[str] = None, tpu_num_cores: Optional[int] = None, tpu_metrics_debug: bool = False, debug: Union[str, list[transformers.debug_utils.DebugOption]] = '', dataloader_drop_last: bool = False, eval_steps: Optional[float] = None, dataloader_num_workers: int = 0, dataloader_prefetch_factor: Optional[int] = None, past_index: int = -1, run_name: Optional[str] = None, disable_tqdm: Optional[bool] = None, remove_unused_columns: Optional[bool] = True, label_names: Optional[list[str]] = None, load_best_model_at_end: Optional[bool] = False, metric_for_best_model: Optional[str] = None, greater_is_better: Optional[bool] = None, ignore_data_skip: bool = False, fsdp: Union[list[transformers.trainer_utils.FSDPOption], str, NoneType] = '', fsdp_min_num_params: int = 0, fsdp_config: Union[dict, str, NoneType] = None, tp_size: Optional[int] = 0, fsdp_transformer_layer_cls_to_wrap: Optional[str] = None, accelerator_config: Union[dict, str, NoneType] = None, deepspeed: Union[dict, str, NoneType] = None, label_smoothing_factor: float = 0.0, optim: Union[transformers.training_args.OptimizerNames, str] = 'adamw_torch', optim_args: Optional[str] = None, adafactor: bool = False, group_by_length: bool = False, length_column_name: Optional[str] = 'length', report_to: Union[NoneType, str, list[str]] = None, ddp_find_unused_parameters: Optional[bool] = None, ddp_bucket_cap_mb: Optional[int] = None, ddp_broadcast_buffers: Optional[bool] = None, dataloader_pin_memory: bool = True, dataloader_persistent_workers: bool = False, skip_memory_metrics: bool = True, use_legacy_prediction_loop: bool = False, push_to_hub: bool = False, resume_from_checkpoint: Optional[str] = None, hub_model_id: Optional[str] = None, hub_strategy: Union[transformers.trainer_utils.HubStrategy, str] = 'every_save', hub_token: Optional[str] = None, hub_private_repo: Optional[bool] = None, hub_always_push: bool = False, gradient_checkpointing: bool = False, gradient_checkpointing_kwargs: Union[dict, str, NoneType] = None, include_inputs_for_metrics: bool = False, include_for_metrics: list[str] = <factory>, eval_do_concat_batches: bool = True, fp16_backend: str = 'auto', push_to_hub_model_id: Optional[str] = None, push_to_hub_organization: Optional[str] = None, push_to_hub_token: Optional[str] = None, mp_parameters: str = '', auto_find_batch_size: bool = False, full_determinism: bool = False, torchdynamo: Optional[str] = None, ray_scope: Optional[str] = 'last', ddp_timeout: Optional[int] = 1800, torch_compile: bool = False, torch_compile_backend: Optional[str] = None, torch_compile_mode: Optional[str] = None, include_tokens_per_second: Optional[bool] = False, include_num_input_tokens_seen: Optional[bool] = False, neftune_noise_alpha: Optional[float] = None, optim_target_modules: Union[NoneType, str, list[str]] = None, batch_eval_metrics: bool = False, eval_on_start: bool = False, use_liger_kernel: Optional[bool] = False, eval_use_gather_object: Optional[bool] = False, average_tokens_across_devices: Optional[bool] = False) -> None\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# NLTK Imports\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:10:21.735693Z","iopub.execute_input":"2025-04-28T15:10:21.736598Z","iopub.status.idle":"2025-04-28T15:10:21.740559Z","shell.execute_reply.started":"2025-04-28T15:10:21.736562Z","shell.execute_reply":"2025-04-28T15:10:21.739925Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# Scikit-learn Imports\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\nfrom sklearn.utils.class_weight import compute_class_weight","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:10:21.742378Z","iopub.execute_input":"2025-04-28T15:10:21.742888Z","iopub.status.idle":"2025-04-28T15:10:21.765678Z","shell.execute_reply.started":"2025-04-28T15:10:21.742866Z","shell.execute_reply":"2025-04-28T15:10:21.765018Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"# Transformers (Hugging Face) Imports \nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset\nfrom transformers import (\n    AutoTokenizer, # Use Auto* classes for flexibility\n    AutoModelForSequenceClassification,\n    Trainer,\n    TrainingArguments,\n    EarlyStoppingCallback\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:10:21.766524Z","iopub.execute_input":"2025-04-28T15:10:21.766801Z","iopub.status.idle":"2025-04-28T15:10:21.787882Z","shell.execute_reply.started":"2025-04-28T15:10:21.766778Z","shell.execute_reply":"2025-04-28T15:10:21.787253Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Disable W&B logging if not used/configured\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n# Set TORCH_USE_CUDA_DSA to avoid potential warning/error on some setups\nos.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:10:21.788717Z","iopub.execute_input":"2025-04-28T15:10:21.789018Z","iopub.status.idle":"2025-04-28T15:10:21.805883Z","shell.execute_reply.started":"2025-04-28T15:10:21.788957Z","shell.execute_reply":"2025-04-28T15:10:21.805324Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"#  Configuration (Simulating config.yaml)\nCONFIG = {\n    'data': {\n        'base_path': \"/kaggle/input/nlp-data\", # Adjust if your dataset name is different\n        'enron_path': \"Enron.csv\",\n        'nigerian_path': \"Nigerian_Fraud.csv\",\n        'spamassassin_path': \"SpamAssasin.csv\",\n        'processed_dir': \"/kaggle/working/processed_data/\",\n        'combined_file': \"combined_emails.parquet\",\n        'text_col': 'text', # Final preprocessed text column name\n        'label_col': 'label',\n        'phishing_label': 1,\n        'legitimate_label': 0,\n    },\n    'preprocessing': {\n        'max_seq_length_bert': 256, # Sequence length for BERT\n    },\n    'feature_engineering': {\n        'tfidf': {\n            'max_features': 5000,\n            'ngram_range': [1, 2], # Uni-grams and Bi-grams\n        },\n    },\n    'training': {\n        'test_size': 0.2,\n        'random_state': 42,\n        'traditional_models': {\n            # Defining models and their parameters for sklearn\n            'Logistic Regression': {'max_iter': 500, 'solver': 'liblinear'}, # liblinear often good for text\n            'Naive Bayes': {},\n            'Random Forest': {'n_estimators': 100, 'random_state': 42, 'n_jobs': -1}, # Use all cores\n            'SVM (Linear)': {'C': 1.0, 'max_iter': 1500, 'dual': False}, # dual=False when n_samples > n_features\n        },\n        'bert': {\n            # Choose a model: 'bert-base-uncased', 'distilbert-base-uncased' (faster, slightly less accurate)\n            'model_name': 'distilbert-base-uncased',\n            'output_dir': '/kaggle/working/bert_training_output', # Checkpoints during training\n            'log_dir': '/kaggle/working/bert_logs',\n            'model_save_dir': '/kaggle/working/bert_model_final', # Final best model\n            'num_epochs': 3, # Start with 3, can increase if needed based on eval logs\n            'batch_size': 16, # Adjust based on GPU memory\n            'learning_rate': 5e-5, # Common starting point for BERT fine-tuning\n            'weight_decay': 0.01,\n            'eval_strategy': \"steps\", # Evaluate during training\n            'eval_steps': 250, # How often to evaluate (adjust based on data size/epochs)\n            'save_steps': 250, # How often to save checkpoints\n            'logging_steps': 50, # How often to log training loss\n            'save_total_limit': 2, # Keep only the best and the last checkpoint\n            'load_best_model_at_end': True, # Crucial: load the best model found during training\n            'metric_for_best_model': 'f1', # Use F1-score on eval set to determine the best model\n            'fp16': torch.cuda.is_available(), # Enable mixed-precision if GPU is available\n        }\n    },\n    'deployment': {\n        # Directory to save artifacts specifically for Streamlit app\n        'export_dir': '/kaggle/working/streamlit_deploy/'\n    }\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:10:21.806748Z","iopub.execute_input":"2025-04-28T15:10:21.807031Z","iopub.status.idle":"2025-04-28T15:10:21.826551Z","shell.execute_reply.started":"2025-04-28T15:10:21.807010Z","shell.execute_reply":"2025-04-28T15:10:21.825907Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# Create Necessary Directories\nos.makedirs(CONFIG['data']['processed_dir'], exist_ok=True)\nos.makedirs(CONFIG['training']['bert']['output_dir'], exist_ok=True)\nos.makedirs(CONFIG['training']['bert']['log_dir'], exist_ok=True)\nos.makedirs(CONFIG['training']['bert']['model_save_dir'], exist_ok=True)\nos.makedirs(CONFIG['deployment']['export_dir'], exist_ok=True)\nprint(\"Output directories created/ensured.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:10:21.827512Z","iopub.execute_input":"2025-04-28T15:10:21.827758Z","iopub.status.idle":"2025-04-28T15:10:21.848131Z","shell.execute_reply.started":"2025-04-28T15:10:21.827742Z","shell.execute_reply":"2025-04-28T15:10:21.847474Z"}},"outputs":[{"name":"stdout","text":"Output directories created/ensured.\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"import nltk # Ensure nltk is imported\n\nprint(\"Downloading NLTK resources...\")\ntry:\n    # Check if the resource exists\n    nltk.data.find('corpora/wordnet.zip') # Check for the zip file existence which is more reliable\nexcept LookupError:\n    # If it doesn't exist, download it\n    print(\"Downloading 'wordnet'...\")\n    nltk.download('wordnet', quiet=True)\ntry:\n    nltk.data.find('corpora/stopwords.zip')\nexcept LookupError:\n    print(\"Downloading 'stopwords'...\")\n    nltk.download('stopwords', quiet=True)\ntry:\n    nltk.data.find('tokenizers/punkt.zip')\nexcept LookupError:\n    print(\"Downloading 'punkt'...\")\n    nltk.download('punkt', quiet=True)\n\nprint(\"NLTK resources downloaded/verified.\")\n\n# These lines should now work fine after the downloads complete (if they were needed)\nstop_words = set(nltk.corpus.stopwords.words('english'))\nlemmatizer = nltk.stem.WordNetLemmatizer()\nprint(\"Stop words and lemmatizer initialized.\")\n\n# Verify lemmatizer works (requires wordnet)\ntry:\n    print(\"Testing lemmatizer:\", lemmatizer.lemmatize(\"cats\"))\nexcept Exception as e:\n    print(f\"Error initializing/testing lemmatizer even after download attempt: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:10:21.850892Z","iopub.execute_input":"2025-04-28T15:10:21.851195Z","iopub.status.idle":"2025-04-28T15:10:21.875166Z","shell.execute_reply.started":"2025-04-28T15:10:21.851177Z","shell.execute_reply":"2025-04-28T15:10:21.874479Z"}},"outputs":[{"name":"stdout","text":"Downloading NLTK resources...\nNLTK resources downloaded/verified.\nStop words and lemmatizer initialized.\nTesting lemmatizer: cat\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"# Preprocessing Functions\ndef clean_text(text):\n    \"\"\"Cleans text data: lowercase, remove URLs, HTML, emails, punctuation, numbers.\"\"\"\n    text = str(text).lower()\n    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", ' ', text) # Remove URLs -> space\n    text = re.sub(r'<.*?>', ' ', text) # Remove HTML tags -> space\n    text = re.sub(r'\\S+@\\S+', ' ', text) # Remove emails -> space\n    text = re.sub(f\"[{re.escape(string.punctuation)}]\", ' ', text) # Remove punctuation -> space\n    text = re.sub(r'\\b\\d+\\b', ' ', text) # Remove standalone numbers -> space\n    text = re.sub(r'\\s+', ' ', text).strip() # Normalize whitespace\n    return text\n\ndef lemmatize_text(text):\n    \"\"\"Tokenizes and lemmatizes text, removing stopwords and short words.\"\"\"\n    tokens = word_tokenize(text)\n    lemmatized = [lemmatizer.lemmatize(w) for w in tokens if w.isalpha() and w not in stop_words and len(w) > 1]\n    return ' '.join(lemmatized)\n\ndef preprocess_dataframe(df, label, text_cols=['subject', 'body']):\n    \"\"\"Standardizes column names, combines text, cleans, and lemmatizes.\"\"\"\n    df = df.copy()\n    # Ensure required columns exist, filling with empty strings if not\n    for col in text_cols:\n        if col not in df.columns:\n            df[col] = ''\n        else:\n            df[col] = df[col].fillna('') # Handle existing NaNs\n\n    # Special handling for DataFrames where the first column might be the body if 'body' is missing\n    if 'body' not in df.columns and df.shape[1] > 0:\n        potential_body_col = df.columns[0]\n        # Heuristic: assume it's the body if it's not 'subject' or another common ID column\n        if potential_body_col not in ['subject', 'id', 'label', 'file']:\n             print(f\"Warning: 'body' column missing. Using first column ('{potential_body_col}') as body.\")\n             df['body'] = df[potential_body_col].fillna('')\n             if 'body' not in text_cols: text_cols.append('body')\n\n    # Combine specified text columns\n    df['combined_text'] = df[text_cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n\n    df[CONFIG['data']['label_col']] = label\n    df['clean_text'] = df['combined_text'].apply(clean_text)\n    # Apply lemmatization to the cleaned text\n    df[CONFIG['data']['text_col']] = df['clean_text'].apply(lemmatize_text)\n\n    # Select and return only the essential final columns\n    df_final = df[[CONFIG['data']['text_col'], CONFIG['data']['label_col']]]\n    return df_final\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:10:21.875954Z","iopub.execute_input":"2025-04-28T15:10:21.876252Z","iopub.status.idle":"2025-04-28T15:10:21.890909Z","shell.execute_reply.started":"2025-04-28T15:10:21.876224Z","shell.execute_reply":"2025-04-28T15:10:21.890333Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"# Data Loading and Caching Function\ndef load_and_process_data(config):\n    \"\"\"Loads raw data, processes it, combines, shuffles, and caches the result.\"\"\"\n    processed_file_path = os.path.join(config['data']['processed_dir'], config['data']['combined_file'])\n\n    if os.path.exists(processed_file_path):\n        print(f\"Loading cached processed data from: {processed_file_path}\")\n        try:\n            return pd.read_parquet(processed_file_path)\n        except Exception as e:\n            print(f\"Error loading cached file: {e}. Reprocessing...\")\n\n    print(\"Processing data from scratch...\")\n    datasets_info = [\n        (config['data']['enron_path'], config['data']['legitimate_label']),\n        (config['data']['nigerian_path'], config['data']['phishing_label']),\n        (config['data']['spamassassin_path'], config['data']['phishing_label']),\n    ]\n\n    all_dfs = []\n    base_path = config['data']['base_path']\n    for file_name, label in datasets_info:\n        path = os.path.join(base_path, file_name)\n        print(f\"--> Processing {file_name}...\")\n        try:\n            # Try reading with utf-8 first, fallback to latin-1\n            try:\n                 raw_df = pd.read_csv(path, on_bad_lines='warn') # 'warn' helps identify issues\n            except UnicodeDecodeError:\n                 print(f\"    UTF-8 failed for {file_name}, trying latin-1...\")\n                 raw_df = pd.read_csv(path, on_bad_lines='warn', encoding='latin-1')\n\n            if raw_df.empty:\n                print(f\"    Warning: {file_name} loaded as empty.\")\n                continue\n\n            processed_df = preprocess_dataframe(raw_df, label)\n            all_dfs.append(processed_df)\n            print(f\"    Processed {len(processed_df)} rows.\")\n        except FileNotFoundError:\n            print(f\"    Error: File not found at {path}\")\n        except Exception as e:\n            print(f\"    Error processing {file_name}: {e}\")\n\n    if not all_dfs:\n        raise ValueError(\"FATAL: No data could be loaded or processed.\")\n\n    print(\"Combining processed datasets...\")\n    combined_df = pd.concat(all_dfs, ignore_index=True)\n    # Drop rows where the processed text or label is missing/empty AFTER processing\n    combined_df.dropna(subset=[config['data']['text_col'], config['data']['label_col']], inplace=True)\n    combined_df = combined_df[combined_df[config['data']['text_col']].str.strip().astype(bool)] # Ensure text isn't just whitespace\n\n    print(f\"Combined data shape before shuffling: {combined_df.shape}\")\n    combined_df = combined_df.sample(frac=1, random_state=config['training']['random_state']).reset_index(drop=True)\n    print(f\"Combined data shape after shuffling: {combined_df.shape}\")\n\n\n    print(f\"Saving combined processed data to: {processed_file_path}\")\n    combined_df.to_parquet(processed_file_path, index=False)\n\n    return combined_df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:10:21.891734Z","iopub.execute_input":"2025-04-28T15:10:21.892082Z","iopub.status.idle":"2025-04-28T15:10:21.914007Z","shell.execute_reply.started":"2025-04-28T15:10:21.892057Z","shell.execute_reply":"2025-04-28T15:10:21.913390Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# Execute Data Loading and Preprocessing\nprint(\"=\"*20 + \" Step 1: Load and Preprocess Data \" + \"=\"*20)\ncombined_df = load_and_process_data(CONFIG)\nprint(f\"\\nFinal data shape: {combined_df.shape}\")\nprint(\"\\nLabel distribution:\")\nprint(combined_df[CONFIG['data']['label_col']].value_counts(normalize=True))\nprint(\"\\nSample data (processed text):\")\nprint(combined_df[[CONFIG['data']['text_col'], CONFIG['data']['label_col']]].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:10:21.914801Z","iopub.execute_input":"2025-04-28T15:10:21.915105Z","iopub.status.idle":"2025-04-28T15:10:22.447588Z","shell.execute_reply.started":"2025-04-28T15:10:21.915082Z","shell.execute_reply":"2025-04-28T15:10:22.446683Z"}},"outputs":[{"name":"stdout","text":"==================== Step 1: Load and Preprocess Data ====================\nLoading cached processed data from: /kaggle/working/processed_data/combined_emails.parquet\n\nFinal data shape: (38905, 2)\n\nLabel distribution:\nlabel\n0    0.765069\n1    0.234931\nName: proportion, dtype: float64\n\nSample data (processed text):\n                                                text  label\n0  get discount vlagra without prescription bodyt...      0\n1  satalk two rule suggestion fri jul justin maso...      1\n2  title dear mr kaminski hope got title right lo...      0\n3  continental power officialisation update curre...      0\n4  capture seventy natural solution fuller firmer...      0\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"#  Train-Test Split \nprint(\"\\n\" + \"=\"*20 + \" Step 2: Train-Test Split \" + \"=\"*20)\ntexts = combined_df[CONFIG['data']['text_col']].tolist()\nlabels = combined_df[CONFIG['data']['label_col']].astype(int).tolist() # Ensure labels are integers\n\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(\n    texts, labels,\n    test_size=CONFIG['training']['test_size'],\n    random_state=CONFIG['training']['random_state'],\n    stratify=labels # Maintain class proportion in train/test sets\n)\nprint(f\"Train size: {len(train_texts)}, Test size: {len(test_texts)}\")\nprint(f\"Train label distribution: {np.mean(train_labels):.2%}\") # Rough check for stratification\nprint(f\"Test label distribution: {np.mean(test_labels):.2%}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:10:22.448639Z","iopub.execute_input":"2025-04-28T15:10:22.449164Z","iopub.status.idle":"2025-04-28T15:10:22.499638Z","shell.execute_reply.started":"2025-04-28T15:10:22.449142Z","shell.execute_reply":"2025-04-28T15:10:22.498793Z"}},"outputs":[{"name":"stdout","text":"\n==================== Step 2: Train-Test Split ====================\nTrain size: 31124, Test size: 7781\nTrain label distribution: 23.49%\nTest label distribution: 23.49%\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"# Feature Engineering (TF-IDF) \nprint(\"\\n\" + \"=\"*20 + \" Step 3: TF-IDF Feature Engineering \" + \"=\"*20)\n\nprint(\"Creating TF-IDF features...\")\ntfidf_vectorizer = TfidfVectorizer(\n    max_features=CONFIG['feature_engineering']['tfidf']['max_features'],\n    ngram_range=tuple(CONFIG['feature_engineering']['tfidf']['ngram_range'])\n)\n\n# Fit on training data ONLY, transform both train and test\nX_train_tfidf = tfidf_vectorizer.fit_transform(train_texts)\nX_test_tfidf = tfidf_vectorizer.transform(test_texts)\n\nprint(f\"TF-IDF Train Matrix shape: {X_train_tfidf.shape}\")\nprint(f\"TF-IDF Test Matrix shape: {X_test_tfidf.shape}\")\n\n# Save the TF-IDF Vectorizer for deployment\ntfidf_save_path = os.path.join(CONFIG['deployment']['export_dir'], 'tfidf_vectorizer.joblib')\njoblib.dump(tfidf_vectorizer, tfidf_save_path)\nprint(f\"\\nTF-IDF Vectorizer saved to: {tfidf_save_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:10:22.500463Z","iopub.execute_input":"2025-04-28T15:10:22.500690Z","iopub.status.idle":"2025-04-28T15:10:44.631650Z","shell.execute_reply.started":"2025-04-28T15:10:22.500672Z","shell.execute_reply":"2025-04-28T15:10:44.630854Z"}},"outputs":[{"name":"stdout","text":"\n==================== Step 3: TF-IDF Feature Engineering ====================\nCreating TF-IDF features...\nTF-IDF Train Matrix shape: (31124, 5000)\nTF-IDF Test Matrix shape: (7781, 5000)\n\nTF-IDF Vectorizer saved to: /kaggle/working/streamlit_deploy/tfidf_vectorizer.joblib\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"# Traditional Model Training \nprint(\"\\n\" + \"=\"*20 + \" Step 4: Train Traditional Models \" + \"=\"*20)\n\ntraditional_results = {}\ntraditional_models = {}\n\nfor name, params in CONFIG['training']['traditional_models'].items():\n    print(f\"\\n--- Training: {name} ---\")\n    start_time = time.time()\n\n    # Select model based on name\n    if name == \"Logistic Regression\":\n        model = LogisticRegression(**params, random_state=CONFIG['training']['random_state'])\n    elif name == \"Naive Bayes\":\n        model = MultinomialNB(**params)\n    elif name == \"Random Forest\":\n        model = RandomForestClassifier(**params)\n    elif name == \"SVM (Linear)\":\n        # LinearSVC is often faster for text classification than SVC(kernel='linear')\n        model = LinearSVC(**params, random_state=CONFIG['training']['random_state'])\n    else:\n        print(f\"Warning: Unknown model type '{name}' defined in config. Skipping.\")\n        continue\n\n    # Train the model\n    model.fit(X_train_tfidf, train_labels)\n\n    # Predict on the test set\n    y_pred = model.predict(X_test_tfidf)\n    end_time = time.time()\n\n    # Evaluate\n    acc = accuracy_score(test_labels, y_pred)\n    report_dict = classification_report(test_labels, y_pred, output_dict=True, zero_division=0)\n    report_str = classification_report(test_labels, y_pred, zero_division=0)\n    cm = confusion_matrix(test_labels, y_pred)\n\n    print(f\"Accuracy: {acc:.4f}\")\n    print(\"Classification Report:\")\n    print(report_str)\n    print(\"Confusion Matrix:\")\n    print(cm)\n    print(f\"Training/Prediction Time: {end_time - start_time:.2f} seconds\")\n\n    # Store results and the trained model\n    traditional_results[name] = {\n        'accuracy': acc,\n        'precision': report_dict['weighted avg']['precision'],\n        'recall': report_dict['weighted avg']['recall'],\n        'f1-score': report_dict['weighted avg']['f1-score'],\n        'report_dict': report_dict,\n        'cm': cm,\n        'time': end_time - start_time\n    }\n    traditional_models[name] = model\n\n# Find and Save the Best Traditional Model\nif traditional_results:\n    best_trad_model_name = max(traditional_results, key=lambda k: traditional_results[k]['f1-score'])\n    best_trad_model = traditional_models[best_trad_model_name]\n    print(f\"\\nBest Traditional Model (by F1-score): {best_trad_model_name}\")\n\n    trad_model_save_path = os.path.join(CONFIG['deployment']['export_dir'], f'traditional_model_{best_trad_model_name.replace(\" \", \"_\").replace(\"(\",\"_\").replace(\")\",\"\").replace(\".\",\"\")}.joblib')\n    joblib.dump(best_trad_model, trad_model_save_path)\n    print(f\"Best Traditional Model saved to: {trad_model_save_path}\")\nelse:\n    print(\"\\nNo traditional models were trained successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:10:44.632781Z","iopub.execute_input":"2025-04-28T15:10:44.633108Z","iopub.status.idle":"2025-04-28T15:11:06.637982Z","shell.execute_reply.started":"2025-04-28T15:10:44.633089Z","shell.execute_reply":"2025-04-28T15:11:06.637286Z"}},"outputs":[{"name":"stdout","text":"\n==================== Step 4: Train Traditional Models ====================\n\n--- Training: Logistic Regression ---\nAccuracy: 0.9477\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.96      0.97      0.97      5953\n           1       0.89      0.88      0.89      1828\n\n    accuracy                           0.95      7781\n   macro avg       0.93      0.93      0.93      7781\nweighted avg       0.95      0.95      0.95      7781\n\nConfusion Matrix:\n[[5758  195]\n [ 212 1616]]\nTraining/Prediction Time: 0.41 seconds\n\n--- Training: Naive Bayes ---\nAccuracy: 0.9239\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.94      0.96      0.95      5953\n           1       0.87      0.79      0.83      1828\n\n    accuracy                           0.92      7781\n   macro avg       0.90      0.88      0.89      7781\nweighted avg       0.92      0.92      0.92      7781\n\nConfusion Matrix:\n[[5736  217]\n [ 375 1453]]\nTraining/Prediction Time: 0.03 seconds\n\n--- Training: Random Forest ---\nAccuracy: 0.9402\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.95      0.97      0.96      5953\n           1       0.90      0.84      0.87      1828\n\n    accuracy                           0.94      7781\n   macro avg       0.93      0.91      0.91      7781\nweighted avg       0.94      0.94      0.94      7781\n\nConfusion Matrix:\n[[5780  173]\n [ 292 1536]]\nTraining/Prediction Time: 20.99 seconds\n\n--- Training: SVM (Linear) ---\nAccuracy: 0.9542\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.97      0.97      0.97      5953\n           1       0.89      0.92      0.90      1828\n\n    accuracy                           0.95      7781\n   macro avg       0.93      0.94      0.94      7781\nweighted avg       0.95      0.95      0.95      7781\n\nConfusion Matrix:\n[[5749  204]\n [ 152 1676]]\nTraining/Prediction Time: 0.41 seconds\n\nBest Traditional Model (by F1-score): SVM (Linear)\nBest Traditional Model saved to: /kaggle/working/streamlit_deploy/traditional_model_SVM__Linear.joblib\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"# ## Step 5: BERT Fine-tuning (Manual PyTorch Loop)\n#\n# This section implements the fine-tuning process using a standard PyTorch loop,\n# bypassing the Hugging Face `Trainer`'s problematic arguments in this environment.\n# This allows for evaluation during training, early stopping, and saving the best model based on F1-score.\n\n# 5.1 Imports for Manual Loop\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW  # ← Correct: Import AdamW from torch.optim\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\nimport numpy as np\nimport os\nimport time\nimport shutil","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:32:50.937517Z","iopub.execute_input":"2025-04-28T15:32:50.937789Z","iopub.status.idle":"2025-04-28T15:32:50.942661Z","shell.execute_reply.started":"2025-04-28T15:32:50.937770Z","shell.execute_reply":"2025-04-28T15:32:50.942035Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"# 5.2 Manual Loop Configuration\n# Using values from the CONFIG dictionary where applicable\nbert_config = CONFIG['training']['bert']\ndata_config = CONFIG['data']\npreproc_config = CONFIG['preprocessing']\ndeploy_config = CONFIG['deployment']\n\nMODEL_NAME = bert_config['model_name']\nMAX_LEN = preproc_config['max_seq_length_bert']\nBATCH_SIZE = bert_config['batch_size']\nEPOCHS = bert_config['num_epochs']\nLEARNING_RATE = bert_config['learning_rate']\n\n# Path to save the best performing model during training\nBEST_MODEL_SAVE_PATH = \"/kaggle/working/best_bert_model.bin\"\n# Directory to save the final best model for deployment\nFINAL_MODEL_SAVE_DIR = deploy_config['export_dir'] # Reuse the deployment dir\n\n# Early stopping parameters\nEARLY_STOPPING_PATIENCE = 3 # Stop after 3 epochs with no improvement\nMIN_DELTA = 0.001 # Minimum change in F1-score to qualify as improvement\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:33:13.538902Z","iopub.execute_input":"2025-04-28T15:33:13.539226Z","iopub.status.idle":"2025-04-28T15:33:13.544661Z","shell.execute_reply.started":"2025-04-28T15:33:13.539203Z","shell.execute_reply":"2025-04-28T15:33:13.544022Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"# 5.3 Load Tokenizer and Model\nprint(f\"Loading Tokenizer and Model: {MODEL_NAME}\")\ntry:\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n    # Ensure num_labels is correct for your phishing task (Binary: 0 or 1)\n    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\nexcept Exception as e:\n    print(f\"Error loading model/tokenizer: {e}\")\n    raise e\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nprint(f\"Using device: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:33:29.166715Z","iopub.execute_input":"2025-04-28T15:33:29.167019Z","iopub.status.idle":"2025-04-28T15:33:29.677359Z","shell.execute_reply.started":"2025-04-28T15:33:29.166988Z","shell.execute_reply":"2025-04-28T15:33:29.676681Z"}},"outputs":[{"name":"stdout","text":"Loading Tokenizer and Model: distilbert-base-uncased\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"# 5.4 Create Dataset and DataLoaders\n# Reusing the EmailDataset class defined earlier\nclass EmailDataset(Dataset):\n    \"\"\"PyTorch Dataset for BERT-like models.\"\"\"\n    def __init__(self, texts, labels, tokenizer, max_len):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = self.labels[idx]\n\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False, # Not needed for BERT/DistilBERT classification\n            padding='max_length',        # Pad to max_length\n            truncation=True,             # Truncate to max_length\n            return_attention_mask=True,\n            return_tensors='pt',         # Return PyTorch tensors\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\nprint(\"Creating datasets...\")\ntrain_dataset = EmailDataset(train_texts, train_labels, tokenizer, MAX_LEN)\ntest_dataset = EmailDataset(test_texts, test_labels, tokenizer, MAX_LEN)\n\nprint(\"Creating dataloaders...\")\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2) # Use num_workers if available\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE * 2, shuffle=False, num_workers=2) # Larger batch size for eval\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:33:52.343794Z","iopub.execute_input":"2025-04-28T15:33:52.344409Z","iopub.status.idle":"2025-04-28T15:33:52.352511Z","shell.execute_reply.started":"2025-04-28T15:33:52.344382Z","shell.execute_reply":"2025-04-28T15:33:52.351679Z"}},"outputs":[{"name":"stdout","text":"Creating datasets...\nCreating dataloaders...\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"# 5.5 Optimizer and Scheduler\nprint(\"Setting up optimizer and learning rate scheduler...\")\noptimizer = AdamW(model.parameters(), lr=LEARNING_RATE, eps=1e-8)\n\n# Calculate total training steps\ntotal_steps = len(train_loader) * EPOCHS\n\n# Create the learning rate scheduler.\nscheduler = get_linear_schedule_with_warmup(optimizer,\n                                            num_warmup_steps = 100, # Number of steps for warmup phase\n                                            num_training_steps = total_steps)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:34:09.562368Z","iopub.execute_input":"2025-04-28T15:34:09.562960Z","iopub.status.idle":"2025-04-28T15:34:09.568472Z","shell.execute_reply.started":"2025-04-28T15:34:09.562938Z","shell.execute_reply":"2025-04-28T15:34:09.567767Z"}},"outputs":[{"name":"stdout","text":"Setting up optimizer and learning rate scheduler...\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"# 5.6 Training and Evaluation Loop\n\nprint(\"\\n\" + \"=\"*20 + \" Starting Training and Evaluation Loop \" + \"=\"*20)\n\nbest_eval_f1 = -1.0 # Initialize best F1 score\nepochs_no_improve = 0 # Counter for early stopping\n\nfor epoch in range(EPOCHS):\n    start_time_epoch = time.time()\n    print(f\"\\n Epoch {epoch + 1}/{EPOCHS} \")\n\n    # --- Training Phase ---\n    model.train() # Set model to training mode\n    total_train_loss = 0\n\n    for batch_num, batch in enumerate(train_loader):\n        # Move batch to GPU\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        # Clear previous gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n\n        # Get loss\n        loss = outputs.loss\n        total_train_loss += loss.item()\n\n        # Backward pass\n        loss.backward()\n\n        # Clip gradients to prevent exploding gradients\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        # Update parameters\n        optimizer.step()\n        # Update learning rate schedule\n        scheduler.step()\n\n        # Print progress (optional)\n        if (batch_num + 1) % 100 == 0:\n             print(f'  Batch {batch_num + 1}/{len(train_loader)} processed. Current Loss: {loss.item():.4f}')\n\n    avg_train_loss = total_train_loss / len(train_loader)\n    print(f\"\\n  Average Training Loss: {avg_train_loss:.4f}\")\n\n    # --- Evaluation Phase ---\n    model.eval() # Set model to evaluation mode\n    total_eval_loss = 0\n    all_preds = []\n    all_labels = []\n\n    print(\"  Starting evaluation on test set...\")\n    with torch.no_grad(): # Disable gradient calculations for evaluation\n        for batch in test_loader:\n            # Move batch to GPU\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            # Forward pass\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n\n            # Accumulate validation loss\n            total_eval_loss += outputs.loss.item()\n\n            # Get predictions (logits)\n            logits = outputs.logits\n            # Move logits and labels to CPU and convert to numpy\n            preds = torch.argmax(logits, dim=1).detach().cpu().numpy()\n            labels_cpu = labels.detach().cpu().numpy()\n\n            all_preds.extend(preds)\n            all_labels.extend(labels_cpu)\n\n    avg_eval_loss = total_eval_loss / len(test_loader)\n\n    # Calculate metrics\n    accuracy = accuracy_score(all_labels, all_preds)\n    # Use weighted F1 for potential class imbalance\n    eval_f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n    report = classification_report(all_labels, all_preds, zero_division=0)\n    cm = confusion_matrix(all_labels, all_preds)\n\n    epoch_time = time.time() - start_time_epoch\n    print(f\"  Average Validation Loss: {avg_eval_loss:.4f}\")\n    print(f\"  Validation Accuracy: {accuracy:.4f}\")\n    print(f\"  Validation F1-score (Weighted): {eval_f1:.4f}\")\n    print(f\"  Epoch completed in: {epoch_time:.2f} seconds\")\n    # print(\"\\n  Classification Report (Test Set):\") # Optional: print full report each epoch\n    # print(report)\n\n    # --- Early Stopping & Best Model Check ---\n    if eval_f1 > best_eval_f1 + MIN_DELTA:\n        print(f\"  Validation F1 improved ({best_eval_f1:.4f} --> {eval_f1:.4f}). Saving model...\")\n        torch.save(model.state_dict(), BEST_MODEL_SAVE_PATH)\n        best_eval_f1 = eval_f1\n        epochs_no_improve = 0\n    else:\n        epochs_no_improve += 1\n        print(f\"  Validation F1 did not improve substantially. ({epochs_no_improve}/{EARLY_STOPPING_PATIENCE})\")\n\n    if epochs_no_improve >= EARLY_STOPPING_PATIENCE:\n        print(f\"\\nEarly stopping triggered after {epoch + 1} epochs.\")\n        break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T15:34:58.421991Z","iopub.execute_input":"2025-04-28T15:34:58.422296Z","iopub.status.idle":"2025-04-28T16:11:24.088882Z","shell.execute_reply.started":"2025-04-28T15:34:58.422273Z","shell.execute_reply":"2025-04-28T16:11:24.087906Z"}},"outputs":[{"name":"stdout","text":"\n==================== Starting Training and Evaluation Loop ====================\n\n Epoch 1/3 \n  Batch 100/1946 processed. Current Loss: 0.2140\n  Batch 200/1946 processed. Current Loss: 0.2192\n  Batch 300/1946 processed. Current Loss: 0.0372\n  Batch 400/1946 processed. Current Loss: 0.0381\n  Batch 500/1946 processed. Current Loss: 0.2723\n  Batch 600/1946 processed. Current Loss: 0.0147\n  Batch 700/1946 processed. Current Loss: 0.0093\n  Batch 800/1946 processed. Current Loss: 0.0190\n  Batch 900/1946 processed. Current Loss: 0.1283\n  Batch 1000/1946 processed. Current Loss: 0.0101\n  Batch 1100/1946 processed. Current Loss: 0.0576\n  Batch 1200/1946 processed. Current Loss: 0.1115\n  Batch 1300/1946 processed. Current Loss: 0.1612\n  Batch 1400/1946 processed. Current Loss: 0.1296\n  Batch 1500/1946 processed. Current Loss: 0.1234\n  Batch 1600/1946 processed. Current Loss: 0.2653\n  Batch 1700/1946 processed. Current Loss: 0.0455\n  Batch 1800/1946 processed. Current Loss: 0.0246\n  Batch 1900/1946 processed. Current Loss: 0.0063\n\n  Average Training Loss: 0.1550\n  Starting evaluation on test set...\n  Average Validation Loss: 0.1174\n  Validation Accuracy: 0.9603\n  Validation F1-score (Weighted): 0.9607\n  Epoch completed in: 726.73 seconds\n  Validation F1 improved (-1.0000 --> 0.9607). Saving model...\n\n Epoch 2/3 \n  Batch 100/1946 processed. Current Loss: 0.2105\n  Batch 200/1946 processed. Current Loss: 0.0063\n  Batch 300/1946 processed. Current Loss: 0.0047\n  Batch 400/1946 processed. Current Loss: 0.0010\n  Batch 500/1946 processed. Current Loss: 0.0026\n  Batch 600/1946 processed. Current Loss: 0.0120\n  Batch 700/1946 processed. Current Loss: 0.0012\n  Batch 800/1946 processed. Current Loss: 0.0108\n  Batch 900/1946 processed. Current Loss: 0.0009\n  Batch 1000/1946 processed. Current Loss: 0.0036\n  Batch 1100/1946 processed. Current Loss: 0.0056\n  Batch 1200/1946 processed. Current Loss: 0.0123\n  Batch 1300/1946 processed. Current Loss: 0.0132\n  Batch 1400/1946 processed. Current Loss: 0.0102\n  Batch 1500/1946 processed. Current Loss: 0.0733\n  Batch 1600/1946 processed. Current Loss: 0.0009\n  Batch 1700/1946 processed. Current Loss: 0.0326\n  Batch 1800/1946 processed. Current Loss: 0.0127\n  Batch 1900/1946 processed. Current Loss: 0.0273\n\n  Average Training Loss: 0.0767\n  Starting evaluation on test set...\n  Average Validation Loss: 0.1285\n  Validation Accuracy: 0.9641\n  Validation F1-score (Weighted): 0.9646\n  Epoch completed in: 728.89 seconds\n  Validation F1 improved (0.9607 --> 0.9646). Saving model...\n\n Epoch 3/3 \n  Batch 100/1946 processed. Current Loss: 0.0039\n  Batch 200/1946 processed. Current Loss: 0.0085\n  Batch 300/1946 processed. Current Loss: 0.0450\n  Batch 400/1946 processed. Current Loss: 0.0011\n  Batch 500/1946 processed. Current Loss: 0.0009\n  Batch 600/1946 processed. Current Loss: 0.0009\n  Batch 700/1946 processed. Current Loss: 0.0669\n  Batch 800/1946 processed. Current Loss: 0.0049\n  Batch 900/1946 processed. Current Loss: 0.0003\n  Batch 1000/1946 processed. Current Loss: 0.0004\n  Batch 1100/1946 processed. Current Loss: 0.0004\n  Batch 1200/1946 processed. Current Loss: 0.0083\n  Batch 1300/1946 processed. Current Loss: 0.2492\n  Batch 1400/1946 processed. Current Loss: 0.1344\n  Batch 1500/1946 processed. Current Loss: 0.0569\n  Batch 1600/1946 processed. Current Loss: 0.0039\n  Batch 1700/1946 processed. Current Loss: 0.0026\n  Batch 1800/1946 processed. Current Loss: 0.0035\n  Batch 1900/1946 processed. Current Loss: 0.1204\n\n  Average Training Loss: 0.0477\n  Starting evaluation on test set...\n  Average Validation Loss: 0.1491\n  Validation Accuracy: 0.9641\n  Validation F1-score (Weighted): 0.9643\n  Epoch completed in: 728.92 seconds\n  Validation F1 did not improve substantially. (1/3)\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"# 5.7 Load the Best Model\n# Load the state dict of the best performing model saved during training\nprint(f\"\\nLoading best model state from: {BEST_MODEL_SAVE_PATH}\")\ntry:\n    model.load_state_dict(torch.load(BEST_MODEL_SAVE_PATH))\n    print(\"Best model loaded successfully.\")\nexcept FileNotFoundError:\n    print(\"Warning: Best model file not found. Using the model state from the last epoch.\")\nexcept Exception as e:\n    print(f\"Error loading best model state: {e}. Using the model state from the last epoch.\")\n\n# %% [code]\n# 5.8 Final Evaluation of the Best Model\n# Run evaluation one last time with the loaded best model to get final metrics\n\nprint(\"\\n\" + \"=\"*10 + \" Final Evaluation of Best Model \" + \"=\"*10)\n\nmodel.eval() # Ensure model is in evaluation mode\nfinal_preds = []\nfinal_labels = []\nfinal_eval_loss = 0\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        final_eval_loss += outputs.loss.item()\n        logits = outputs.logits\n        preds = torch.argmax(logits, dim=1).detach().cpu().numpy()\n        labels_cpu = labels.detach().cpu().numpy()\n\n        final_preds.extend(preds)\n        final_labels.extend(labels_cpu)\n\n# Calculate final metrics\nfinal_avg_loss = final_eval_loss / len(test_loader)\nfinal_accuracy = accuracy_score(final_labels, final_preds)\nfinal_f1 = f1_score(final_labels, final_preds, average='weighted', zero_division=0)\nfinal_report = classification_report(final_labels, final_preds, zero_division=0, target_names=['Legitimate (0)', 'Phishing (1)']) # Adjust target names if needed\nfinal_cm = confusion_matrix(final_labels, final_preds)\n\nprint(f\"\\nFinal Evaluation Metrics (Best Model on Test Set):\")\nprint(f\"  Average Loss: {final_avg_loss:.4f}\")\nprint(f\"  Accuracy: {final_accuracy:.4f}\")\nprint(f\"  F1-score (Weighted): {final_f1:.4f}\")\nprint(\"\\nClassification Report (Best Model):\")\nprint(final_report)\nprint(\"\\nConfusion Matrix (Best Model):\")\nprint(final_cm)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T16:11:24.090703Z","iopub.execute_input":"2025-04-28T16:11:24.090999Z","iopub.status.idle":"2025-04-28T16:12:18.772906Z","shell.execute_reply.started":"2025-04-28T16:11:24.090952Z","shell.execute_reply":"2025-04-28T16:12:18.772124Z"}},"outputs":[{"name":"stdout","text":"\nLoading best model state from: /kaggle/working/best_bert_model.bin\nBest model loaded successfully.\n\n========== Final Evaluation of Best Model ==========\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/2239114596.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(BEST_MODEL_SAVE_PATH))\n","output_type":"stream"},{"name":"stdout","text":"\nFinal Evaluation Metrics (Best Model on Test Set):\n  Average Loss: 0.1285\n  Accuracy: 0.9641\n  F1-score (Weighted): 0.9646\n\nClassification Report (Best Model):\n                precision    recall  f1-score   support\n\nLegitimate (0)       0.99      0.97      0.98      5953\n  Phishing (1)       0.89      0.96      0.93      1828\n\n      accuracy                           0.96      7781\n     macro avg       0.94      0.96      0.95      7781\n  weighted avg       0.97      0.96      0.96      7781\n\n\nConfusion Matrix (Best Model):\n[[5747  206]\n [  73 1755]]\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"# 5.9 Save Final BERT Model and Tokenizer for Deployment\n# Save the BEST model (currently loaded) and the tokenizer\n\nbert_deploy_path = os.path.join(FINAL_MODEL_SAVE_DIR, 'bert_model')\nprint(f\"\\nSaving final best BERT model and tokenizer for deployment to: {bert_deploy_path}\")\n\ntry:\n    # Ensure the target directory exists and is empty for a clean save\n    if os.path.exists(bert_deploy_path):\n        print(f\"  Removing existing deployment directory: {bert_deploy_path}\")\n        shutil.rmtree(bert_deploy_path)\n    os.makedirs(bert_deploy_path, exist_ok=True)\n\n    # Use Hugging Face's save_pretrained method for both model and tokenizer\n    model.save_pretrained(bert_deploy_path)\n    tokenizer.save_pretrained(bert_deploy_path)\n    print(\"Best model and tokenizer saved successfully for deployment.\")\n\nexcept Exception as e:\n    print(f\"\\nError saving final model/tokenizer for deployment: {e}\")\n    import traceback\n    traceback.print_exc()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T16:12:18.773789Z","iopub.execute_input":"2025-04-28T16:12:18.774004Z","iopub.status.idle":"2025-04-28T16:12:19.256610Z","shell.execute_reply.started":"2025-04-28T16:12:18.773982Z","shell.execute_reply":"2025-04-28T16:12:19.255722Z"}},"outputs":[{"name":"stdout","text":"\nSaving final best BERT model and tokenizer for deployment to: /kaggle/working/streamlit_deploy/bert_model\nBest model and tokenizer saved successfully for deployment.\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"import os\nimport shutil\nimport time\n\nprint(\"\\n\" + \"=\"*20 + \" Archiving /kaggle/working/ \" + \"=\"*20)\n\n# Define the directory to archive and the name of the output zip file\nsource_dir = \"/kaggle/working/\"\n# Place the archive file directly inside /kaggle/working/ for easy UI access\noutput_filename = os.path.join(source_dir, \"kaggle_working_archive\") # shutil adds .zip automatically\n\ntry:\n    print(f\"Attempting to create archive: {output_filename}.zip\")\n    # Create the zip archive. shutil.make_archive handles finding files within source_dir.\n    # We specify source_dir as the root_dir to get the contents directly,\n    # rather than a folder named 'working' inside the zip.\n    shutil.make_archive(base_name=output_filename,\n                        format='zip',\n                        root_dir=source_dir)\n\n    print(f\"\\nSuccessfully created archive: {output_filename}.zip\")\n    print(\"\\n--- DOWNLOAD INSTRUCTIONS ---\")\n    print(\"1. Go to the 'Data' tab in the right-hand panel of this notebook.\")\n    print(\"2. Navigate to the 'Output' section, then '/kaggle/working/'.\")\n    print(f\"3. Find the file named 'kaggle_working_archive.zip'.\")\n    print(\"4. Click the three dots (...) next to the file and select 'Download'.\")\n    print(\"5. Unzip this file on your local machine to get all contents, including the 'streamlit_deploy' folder.\")\n    print(\"-----------------------------\")\n\nexcept Exception as e:\n    print(f\"\\n--- ERROR creating archive ---\")\n    print(f\"An error occurred: {e}\")\n    import traceback\n    traceback.print_exc()\n    print(\"-----------------------------\")\n    print(\"Please try downloading the 'streamlit_deploy' folder manually from the Output section.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T16:49:50.550418Z","iopub.execute_input":"2025-04-28T16:49:50.551127Z","iopub.status.idle":"2025-04-28T17:03:06.325821Z","shell.execute_reply.started":"2025-04-28T16:49:50.551101Z","shell.execute_reply":"2025-04-28T17:03:06.324877Z"}},"outputs":[{"name":"stdout","text":"\n==================== Archiving /kaggle/working/ ====================\nAttempting to create archive: /kaggle/working/kaggle_working_archive.zip\n\n--- ERROR creating archive ---\nAn error occurred: [Errno 28] No space left on device\n-----------------------------\nPlease try downloading the 'streamlit_deploy' folder manually from the Output section.\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/usr/lib/python3.11/zipfile.py\", line 1815, in write\n    shutil.copyfileobj(src, dest, 1024*8)\n  File \"/usr/lib/python3.11/shutil.py\", line 200, in copyfileobj\n    fdst_write(buf)\n  File \"/usr/lib/python3.11/zipfile.py\", line 1180, in write\n    self._fileobj.write(data)\nOSError: [Errno 28] No space left on device\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/shutil.py\", line 1046, in _make_zipfile\n    zf.write(path, arcname)\n  File \"/usr/lib/python3.11/zipfile.py\", line 1814, in write\n    with open(filename, \"rb\") as src, self.open(zinfo, 'w') as dest:\n  File \"/usr/lib/python3.11/zipfile.py\", line 1201, in close\n    raise RuntimeError(\"File size too large, try using force_zip64\")\nRuntimeError: File size too large, try using force_zip64\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/zipfile.py\", line 1912, in close\n    self.fp.seek(self.start_dir)\nOSError: [Errno 28] No space left on device\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/tmp/ipykernel_31/1489873221.py\", line 17, in <cell line: 0>\n    shutil.make_archive(base_name=output_filename,\n  File \"/usr/lib/python3.11/shutil.py\", line 1165, in make_archive\n    filename = func(base_name, base_dir, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/shutil.py\", line 1020, in _make_zipfile\n    with zipfile.ZipFile(zip_filename, \"w\",\n  File \"/usr/lib/python3.11/zipfile.py\", line 1356, in __exit__\n    self.close()\n  File \"/usr/lib/python3.11/zipfile.py\", line 1917, in close\n    self._fpclose(fp)\n  File \"/usr/lib/python3.11/zipfile.py\", line 2017, in _fpclose\n    fp.close()\nOSError: [Errno 28] No space left on device\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"# --- Cleanup Large Non-Essential Directories and Failed Archives ---\nimport os\nimport shutil\nimport glob # To find zip files\n\nprint(\"Starting cleanup of /kaggle/working/ ...\")\n\n# Directories to remove (Modify if your paths were different)\ndirs_to_remove = [\n    \"/kaggle/working/bert_training_output/\",  # Intermediate training checkpoints\n    \"/kaggle/working/processed_data/\",       # Processed data cache\n    \"/kaggle/working/bert_logs/\",             # Training logs\n    \"/kaggle/working/bert_model_final/\"       # Final model before copy (assuming streamlit_deploy/bert_model is complete)\n]\n\n# Files/Patterns to remove (Failed archives)\nfiles_to_remove_patterns = [\n    \"/kaggle/working/*.zip\"                   # Any zip file in /kaggle/working/\n]\n\n# --- Remove Directories ---\nprint(\"\\nAttempting to remove directories:\")\nfor dir_path in dirs_to_remove:\n    if os.path.exists(dir_path) and os.path.isdir(dir_path):\n        try:\n            print(f\"  Removing directory: {dir_path}\")\n            shutil.rmtree(dir_path)\n            print(f\"  Successfully removed.\")\n        except Exception as e:\n            print(f\"  ERROR removing {dir_path}: {e}\")\n            print(\"    Might need manual removal via UI if possible, or ignore if download works.\")\n    else:\n        print(f\"  Directory not found, skipping: {dir_path}\")\n\n# --- Remove Files matching patterns ---\nprint(\"\\nAttempting to remove files:\")\nfor pattern in files_to_remove_patterns:\n    found_files = glob.glob(pattern)\n    if not found_files:\n        print(f\"  No files found matching pattern: {pattern}\")\n        continue\n    for file_path in found_files:\n        if os.path.exists(file_path) and os.path.isfile(file_path):\n            try:\n                print(f\"  Removing file: {file_path}\")\n                file_size = os.path.getsize(file_path) / (1024**2) # Size in MiB\n                os.remove(file_path)\n                print(f\"  Successfully removed (approx {file_size:.1f} MiB).\")\n            except Exception as e:\n                print(f\"  ERROR removing {file_path}: {e}\")\n        else:\n             print(f\"  File not found or is not a file, skipping: {file_path}\")\n\n\nprint(\"\\nCleanup attempt finished.\")\nprint(\"Please verify the contents of '/kaggle/working/streamlit_deploy/' via the UI.\")\nprint(\"Proceed with MANUAL download of the required files from '/kaggle/working/streamlit_deploy/'.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T17:07:18.133225Z","iopub.execute_input":"2025-04-28T17:07:18.133514Z","iopub.status.idle":"2025-04-28T17:07:20.492492Z","shell.execute_reply.started":"2025-04-28T17:07:18.133498Z","shell.execute_reply":"2025-04-28T17:07:20.491817Z"}},"outputs":[{"name":"stdout","text":"Starting cleanup of /kaggle/working/ ...\n\nAttempting to remove directories:\n  Removing directory: /kaggle/working/bert_training_output/\n  Successfully removed.\n  Removing directory: /kaggle/working/processed_data/\n  Successfully removed.\n  Removing directory: /kaggle/working/bert_logs/\n  Successfully removed.\n  Removing directory: /kaggle/working/bert_model_final/\n  Successfully removed.\n\nAttempting to remove files:\n  Removing file: /kaggle/working/kaggle_working_archive.zip\n  Successfully removed (approx 19408.5 MiB).\n\nCleanup attempt finished.\nPlease verify the contents of '/kaggle/working/streamlit_deploy/' via the UI.\nProceed with MANUAL download of the required files from '/kaggle/working/streamlit_deploy/'.\n","output_type":"stream"}],"execution_count":75}]}